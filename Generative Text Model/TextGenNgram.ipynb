{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuiMbRJ-fxvw"
      },
      "source": [
        "# CSC 820 HW #5\n",
        "## Khalid Mehtab Khan\n",
        "## SFSU ID: 923673423\n",
        "\n",
        "- All the comments and explanation in the notebook are added as text markdown\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXotLqN1RBVL",
        "outputId": "8c6df9d2-2999-4f82-e7ce-e68da4f6d060"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mDEPRECATION: Loading egg at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/QualiGPTApp-0.1-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: dill in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.3.9)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -U dill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4ZWC9IqRFzC",
        "outputId": "bad466db-896e-4ab3-c62c-7bf213eb2589"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mDEPRECATION: Loading egg at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/QualiGPTApp-0.1-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting nltk==3.4\n",
            "  Using cached nltk-3.4-py3-none-any.whl\n",
            "Requirement already satisfied: six in /Users/khalidkhan/Library/Python/3.12/lib/python/site-packages (from nltk==3.4) (1.16.0)\n",
            "Requirement already satisfied: singledispatch in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk==3.4) (4.1.0)\n",
            "Installing collected packages: nltk\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.9.1\n",
            "    Uninstalling nltk-3.9.1:\n",
            "      Successfully uninstalled nltk-3.9.1\n",
            "Successfully installed nltk-3.4\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -U nltk==3.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrUXAglJ3icm",
        "outputId": "cd1f292c-9287-4fe5-fb6b-bbe83fc07601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mDEPRECATION: Loading egg at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/QualiGPTApp-0.1-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.4)\n",
            "Collecting nltk\n",
            "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk) (4.66.5)\n",
            "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "Installing collected packages: nltk\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.4\n",
            "    Uninstalling nltk-3.4:\n",
            "      Successfully uninstalled nltk-3.4\n",
            "Successfully installed nltk-3.9.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Upgrading NLTK is necessary to fix errors related to padded sequences.\n",
        "# This update ensures that all required imports work properly.\n",
        "\n",
        "# if the session is restarted becuase of this, please upgrade nltk before moving ahead\n",
        "\n",
        "!pip install --upgrade nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HvtVIRrjbjO"
      },
      "source": [
        "---------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixpRQ0_xX7Hc"
      },
      "source": [
        "Import necessary functions from NLTK for text preprocessing, including padding, and creating bigrams, ngrams, and everygrams for language modeling.\n",
        "\n",
        "- 'pad_sequence' for adding start or end padding to word sequences.\n",
        "- 'bigrams' for creating pairs of adjacent words.\n",
        "- 'ngrams' for making groups of words up to a specified number.\n",
        "- 'everygrams' for generating all possible word combinations.\n",
        "- 'pad_both_ends' for adding specific markers to indicate the beginning and end of sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "duGm-LLRjqdj"
      },
      "outputs": [],
      "source": [
        "from nltk.util import pad_sequence\n",
        "from nltk.util import bigrams\n",
        "from nltk.util import ngrams\n",
        "from nltk.util import everygrams\n",
        "from nltk.lm.preprocessing import pad_both_ends\n",
        "from nltk.lm.preprocessing import flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYWEcZ7CmvR7",
        "outputId": "2cc5c16c-c738-4a6c-8cae-4ca38d38d0ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/khalidkhan/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUJsMGOOYMzQ"
      },
      "source": [
        "Import pandas for data manipulation, and NLTK's tokenization functions for splitting text into words and sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wusahzKql62h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from nltk import word_tokenize, sent_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXZ6ra5oYRR7"
      },
      "source": [
        "Import language modeling tools from NLTK: 'padded_everygram_pipeline' for preparing text data, and 'MLE' for creating a language model using the Maximum Likelihood Estimation approach.\n",
        "\n",
        "- 'padded_everygram_pipeline' for preparing text data with padding and generating n-grams for language modeling.\n",
        "- 'MLE' from NLTK for creating a language model using the Maximum Likelihood Estimation method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "d9GTX4xVm3dW"
      },
      "outputs": [],
      "source": [
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.lm import MLE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFhx-T804nZS"
      },
      "source": [
        "This example shows how the bigram function turns arrays of words into pairs called bigrams.\n",
        "\n",
        "- Each pair is made from words in the same sentence, not from different sentences. This helps us understand the sentence better and improves our predictions for the next words.\n",
        "\n",
        "We create two example sentences split into individual words. This setup helps us learn how tasks like breaking down text and forming word pairs work in language processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "BH4dGU9ejuQv"
      },
      "outputs": [],
      "source": [
        "text = [['I','need','to','book', 'ticket', 'to', 'Australia' ], ['I', 'want', 'to' ,'read', 'a' ,'book', 'of' ,'Shakespeare']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-JIpcZRq40q"
      },
      "source": [
        "We can see in context of our padded language model sentences, that these bigrams are without \"s\" marking at the beginning and the '/s' end of the sentence because no preprocessing of the text has been done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXbTTKZbkxdN",
        "outputId": "cad7d887-74a8-4d7f-b063-ccf4d9704a17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('I', 'need'),\n",
              " ('need', 'to'),\n",
              " ('to', 'book'),\n",
              " ('book', 'ticket'),\n",
              " ('ticket', 'to'),\n",
              " ('to', 'Australia')]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(bigrams(text[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xxbu2m1a5N5q"
      },
      "source": [
        "Trigrams can be used in a similar way\n",
        "\n",
        "- Generate trigrams from the second sentence in our text. This is an example of how to produce n-grams of length three from a sequence of tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hg09C7CVkzZr",
        "outputId": "4c9995f4-e3a0-4d15-af31-87fd7dc4331e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('I', 'want', 'to'),\n",
              " ('want', 'to', 'read'),\n",
              " ('to', 'read', 'a'),\n",
              " ('read', 'a', 'book'),\n",
              " ('a', 'book', 'of'),\n",
              " ('book', 'of', 'Shakespeare')]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(ngrams(text[1], n=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WygI_inE22RC"
      },
      "source": [
        "- As this project was setup on google colab, the dataset was upload on the drive, if data is used in any other way please change the next two blocks of code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YEOuJlnldeE",
        "outputId": "589c3f82-0dd4-441e-a412-6ccd413f2ae3"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "_m5OyAkTl3mV",
        "outputId": "3b79ca73-0ede-4c05-fc6e-aa7a022150d2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>link</th>\n",
              "      <th>content</th>\n",
              "      <th>date</th>\n",
              "      <th>retweets</th>\n",
              "      <th>favorites</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1698308935</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/169...</td>\n",
              "      <td>Be sure to tune in and watch Donald Trump on L...</td>\n",
              "      <td>2009-05-04 13:54:25</td>\n",
              "      <td>510</td>\n",
              "      <td>917</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1701461182</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/170...</td>\n",
              "      <td>Donald Trump will be appearing on The View tom...</td>\n",
              "      <td>2009-05-04 20:00:10</td>\n",
              "      <td>34</td>\n",
              "      <td>267</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1737479987</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/173...</td>\n",
              "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
              "      <td>2009-05-08 08:38:08</td>\n",
              "      <td>13</td>\n",
              "      <td>19</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1741160716</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/174...</td>\n",
              "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
              "      <td>2009-05-08 15:40:15</td>\n",
              "      <td>11</td>\n",
              "      <td>26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1773561338</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/177...</td>\n",
              "      <td>\"My persona will never be that of a wallflower...</td>\n",
              "      <td>2009-05-12 09:07:28</td>\n",
              "      <td>1375</td>\n",
              "      <td>1945</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id                                               link  \\\n",
              "0  1698308935  https://twitter.com/realDonaldTrump/status/169...   \n",
              "1  1701461182  https://twitter.com/realDonaldTrump/status/170...   \n",
              "2  1737479987  https://twitter.com/realDonaldTrump/status/173...   \n",
              "3  1741160716  https://twitter.com/realDonaldTrump/status/174...   \n",
              "4  1773561338  https://twitter.com/realDonaldTrump/status/177...   \n",
              "\n",
              "                                             content                 date  \\\n",
              "0  Be sure to tune in and watch Donald Trump on L...  2009-05-04 13:54:25   \n",
              "1  Donald Trump will be appearing on The View tom...  2009-05-04 20:00:10   \n",
              "2  Donald Trump reads Top Ten Financial Tips on L...  2009-05-08 08:38:08   \n",
              "3  New Blog Post: Celebrity Apprentice Finale and...  2009-05-08 15:40:15   \n",
              "4  \"My persona will never be that of a wallflower...  2009-05-12 09:07:28   \n",
              "\n",
              "   retweets  favorites mentions hashtags  \n",
              "0       510        917      NaN      NaN  \n",
              "1        34        267      NaN      NaN  \n",
              "2        13         19      NaN      NaN  \n",
              "3        11         26      NaN      NaN  \n",
              "4      1375       1945      NaN      NaN  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trump_tweet_data = pd.read_csv('realdonaldtrump.csv')\n",
        "trump_tweet_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EtDyAy-b5IJ",
        "outputId": "84045e0e-d33a-4e77-f30c-642cbd2f5886"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'link', 'content', 'date', 'retweets', 'favorites', 'mentions',\n",
              "       'hashtags'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# using the columns method of data frame, we can anlayse what types of information the data frame provides\n",
        "trump_tweet_data.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1hDTykT5XC0"
      },
      "source": [
        "Importing Dataset from drive\n",
        "\n",
        "- Here we load a dataset of Donald Trump's tweets using pandas, which is a tool for data manipulation. We then display the first few rows of the dataset with '.head()' to see what the data looks like and identify the columns, especially where the tweets are stored\n",
        "\n",
        "In the data frame, each row represents a tweet. The dataframe provides more infromation aeach tweets which can be seen as the columns of the data.\n",
        "\n",
        "Each tweet has -\n",
        "  'id',\n",
        "  'link',\n",
        "  'content',\n",
        "  'date',\n",
        "  'retweets',\n",
        "  'favorites',\n",
        "  'mentions',\n",
        "  'hashtags'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0T67WEnmCTq",
        "outputId": "0dfab075-fcf3-455c-d116-2fbd8b86e460"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "43352"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trump_tokens = list(trump_tweet_data[\"content\"].apply(word_tokenize))\n",
        "len(trump_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zahH8jodZ86W"
      },
      "source": [
        "Using nltk word tokenizer to tokenize each row of the content column\n",
        "\n",
        "- We take the column with tweets, which is 'content', and apply 'word_tokenize' to split each tweet into individual word strings. We store these lists of words in 'trump_tokens'.\n",
        "\n",
        "We can check how many tweets (lists of words) we have by measuring the length of 'trump_tokens'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi666ZJtnlCH",
        "outputId": "9e1957c1-9905-4f0e-c87e-7e861f01f3a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Be',\n",
              " 'sure',\n",
              " 'to',\n",
              " 'tune',\n",
              " 'in',\n",
              " 'and',\n",
              " 'watch',\n",
              " 'Donald',\n",
              " 'Trump',\n",
              " 'on',\n",
              " 'Late',\n",
              " 'Night',\n",
              " 'with',\n",
              " 'David',\n",
              " 'Letterman',\n",
              " 'as',\n",
              " 'he',\n",
              " 'presents',\n",
              " 'the',\n",
              " 'Top',\n",
              " 'Ten',\n",
              " 'List',\n",
              " 'tonight',\n",
              " '!']"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trump_tokens[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL5PgOeaR8Gj"
      },
      "source": [
        "To get a clearer idea of how the tweets have been split into words, we look at the first tokenized tweet. This helps us see the result of the tokenization process\n",
        "\n",
        "- We can see there are 43352 sentences in the content column\n",
        "- Each sentence has its own array of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "zE37gHXjnr6f"
      },
      "outputs": [],
      "source": [
        "n = 3\n",
        "train_data, padded_sents = padded_everygram_pipeline(n, trump_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TWKneCS9prx"
      },
      "source": [
        "# Model Training: Phase 1 Pre-Processing\n",
        "\n",
        "- Here we start preparing our tweets to build a language model. We decide on using sequences up to three words long (that's what 'n = 3'). When the value of everygram is specified the function create word sequences of length less than or equal to the specified values. The padded_everygram_pipeline function helps us format these tweets correctly for our language model.\n",
        "\n",
        "- This function adds padding to the start and end of each tweet to handle the beginnings and endings of each setnence to keep context properly.\n",
        "\n",
        "- The 'train_data' variable will be used for training, while 'padded_sents' contains our processed tweets.\n",
        "\n",
        "## train_data\n",
        "- It is a series of everygram sequences derived from the input text, In this case we using n = 3 which will create sequences of all lenghts less than or equal to n to calculate probabliities.\n",
        "\n",
        "- As the intuitive name everygram suggests, it contains all the n-grams of length less than or equal to the specified values of n.\n",
        "\n",
        "In this case it will create all unigrams, bigrams and trigram possible for each sentence\n",
        "eg:\n",
        "\n",
        "    ('<s>',),\n",
        "    ('<s>', '<s>'),\n",
        "    ('<s>', '<s>', 'Be'),\n",
        "    ('<s>',), ('<s>', 'Be'),\n",
        "    ('<s>', 'Be', 'sure'),\n",
        "    ('Be',),\n",
        "    ('Be', 'sure'),\n",
        "    ('Be', 'sure', 'to'),\n",
        "    ('sure',),\n",
        "    ('sure', 'to'),\n",
        "    ('sure', 'to', 'tune'),\n",
        "    ('to',),\n",
        "    ('to', 'tune'),\n",
        "    ('to', 'tune', 'in'),\n",
        "    ('tune',),\n",
        "    ('tune', 'in'),\n",
        "    ('tune', 'in', 'and'),\n",
        "    ('in',), ('in', 'and'),\n",
        "    ('in', 'and', 'watch'),\n",
        "    ('and',), ('and', 'watch'),\n",
        "    ('and', 'watch', 'Donald'),\n",
        "    ('watch',),\n",
        "    ('watch', 'Donald'),\n",
        "    ('watch', 'Donald', 'Trump')\n",
        "\n",
        "  and so on\n",
        "\n",
        "## 'padded_sents'\n",
        " - contains our tweets after they've been processed. Each one starts and ends with markers like 's' and '/s', signaling the beginning and end of sentences.\n",
        "\n",
        " - This detailed structure helps our model understand context better.\n",
        "\n",
        " eg:\n",
        "    's',\n",
        "    's',\n",
        "    'Be',\n",
        "    'sure',\n",
        "    'to',\n",
        "    'tune',\n",
        "    'in',\n",
        "    'and',\n",
        "    'watch',\n",
        "    'Donald',\n",
        "    'Trump',\n",
        "    'on',\n",
        "    'Late',\n",
        "    'Night',\n",
        "    'with',\n",
        "    'David',\n",
        "    'Letterman',\n",
        "    'as',\n",
        "    'he',\n",
        "    'presents',\n",
        "    'the',\n",
        "    'Top',\n",
        "    'Ten',\n",
        "    'List',\n",
        "    'tonight',\n",
        "    '!',\n",
        "    '/s',\n",
        "    '/s',\n",
        "    's',\n",
        "    's',\n",
        "    'Donald',\n",
        "    'Trump',\n",
        "    'will',"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkyXJrdYfwPr"
      },
      "source": [
        "Initialize our language model using the Maximum Likelihood Estimation (MLE) method with 'n' (the number of words to consider, which we set to 3). Then, train the model using our prepared 'train_data' to learn from the tweet sequences.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "HaSxYGfDnr3f"
      },
      "outputs": [],
      "source": [
        "trump_model = MLE(n)\n",
        "trump_model.fit(train_data, padded_sents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKzcNZFUv9xr"
      },
      "source": [
        "# Model Training: Phase 2 Training\n",
        "\n",
        "- We utilize MLE here to estimate the parameters of our language model.\n",
        "- the estimation method calculates the probability of observing the data given a set of parameters.\n",
        "- We employ MLE as it helps in determining the most likely parameters that make the observed data most probable.\n",
        "\n",
        "- 'fit' method trains 'trump_model' using 'train_data' and 'padded_sents', adapting the model to learn from the training dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBSRPtAff1Zh"
      },
      "source": [
        "# Generating Setences\n",
        "\n",
        "As the name De-tokenizer suggest, It helps us turn lists of words back into full sentences, making them easy to read."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "G7NZNq0mnr1J"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "# Instance of detokenizer\n",
        "detokenize = TreebankWordDetokenizer().detokenize\n",
        "\n",
        "def generate_sent(model, num_words, random_seed=42):\n",
        "    \"\"\"\n",
        "    :param model: An ngram language model from `nltk.lm.model`.\n",
        "    :param num_words: Max no. of words to generate.\n",
        "    :param random_seed: Seed value for random.\n",
        "    \"\"\"\n",
        "    content = []\n",
        "    for token in model.generate(num_words, random_seed=random_seed):\n",
        "        if token == '<s>':\n",
        "            continue\n",
        "        if token == '</s>':\n",
        "            break\n",
        "        content.append(token)\n",
        "    return detokenize(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN-bl1cugcFk"
      },
      "source": [
        "- The generate_sent function returns new sentences by choosing words one by one, aiming for a maximum length of up to n words per sentence.\n",
        "\n",
        "- The function takes in\n",
        "    - a model,\n",
        "    - max number of words and\n",
        "    - a random number distribtution seed,\n",
        "  \n",
        "  which has been set to a default value 42 if the user provides no input for the seed.\n",
        "\n",
        "- The function works on the word pair probabilities and language patterns extracted from Trump's tweets during the model training phase.\n",
        "\n",
        "- The function skips special markers 's' and '/s' that usually indicate the start and end of sentences. The later marks the end of the sentence and once we a '/s' we break and return a compelete sentence.\n",
        "\n",
        "- Once we have all our words, we join them into one complete sentence using the detokenize function and return it.\n",
        "\n",
        "- This way, each new sentence generated mirrors the linguistic style observed in the original dataset of tweets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0zLaqrXdACx"
      },
      "source": [
        "# Generated Sentence Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qwqUyrhhxRdj",
        "outputId": "9416e25e-9658-44a0-e904-18079e35b065"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'for 200 years . Thank you'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_sent(trump_model, num_words=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJFfxecoxRxn"
      },
      "source": [
        "- generate_sent(trump_model, num_words=4)\n",
        "\n",
        "- Using the num_words as 6 for a short sentence\n",
        "- As we did not specify any seed, the randon_seed will take the default value of 42\n",
        "\n",
        " ### Generated Sentence\n",
        "-  'for 200 years . Thank you'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "A9tiVaKOnryn",
        "outputId": "b0d33126-69fb-4e99-a3af-6756751a257a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'with his family and many thousands of energy and excitement'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_sent(trump_model, num_words=10, random_seed=56)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTc1nY_xxCcL"
      },
      "source": [
        "- generate_sent(trump_model, num_words=10, random_seed=56)\n",
        "\n",
        "\n",
        " ### Generated Sentence\n",
        "-  'with his family and many thousands of energy and excitement'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VgWst8xfoJ6n",
        "outputId": "ede02062-bbd6-4293-a768-eea1ef0d3598"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Trump_Ireland graces over 500 acres fronting 2.5 miles . Extraordinary! http: //bit.ly/jyfGP3 #celebrityapprenticefinale'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_sent(trump_model, num_words=20, random_seed=112)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihFFCtvbxhfp"
      },
      "source": [
        "- generate_sent(trump_model, num_words=20, random_seed=112)\n",
        "\n",
        "We use the generate random functio nwith the same model but with the length of sentence specified as 20 and random numbers seed as 112\n",
        "\n",
        " ### Generated Sentence\n",
        "- Trump_Ireland graces over 500 acres fronting 2.5 miles . Extraordinary! http: //bit.ly/jyfGP3 #celebrityapprenticefinale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYmyS52lyfIJ"
      },
      "source": [
        "# Limitations\n",
        "\n",
        "- If we specify a length too long the model will generate a sentece that might not make sence after a while, becuase the model tries to keep the context of words to a sentence, Also, in general most sentences are not very long.\n",
        "\n",
        "- The model works better with short sentence lengths\n",
        "\n",
        "- For the same random seed the model will keep generating same sequence of words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuTpkagTkFdl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
