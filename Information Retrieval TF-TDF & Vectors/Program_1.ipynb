{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSC 820 NLT\n",
    "## HW11\n",
    "* > Khalid Mehtab Khan\n",
    "* > 923673423\n",
    "\n",
    "## Program_1\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015843,
     "end_time": "2021-03-10T09:03:36.533752",
     "exception": false,
     "start_time": "2021-03-10T09:03:36.517909",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Text Mining : TF-IDF and Cosine Similarity from Scratch\n",
    "\n",
    "Table of Contents:\n",
    "\n",
    "1. Term Frequency (TF)\n",
    "2. Inverse Document Frequency (IDF)\n",
    "3. TF * IDF\n",
    "4. Vector Space Models and Representation – Cosine Similarity\n",
    "\n",
    "*** Any feedback or feature requests are welcome!***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014249,
     "end_time": "2021-03-10T09:03:36.562996",
     "exception": false,
     "start_time": "2021-03-10T09:03:36.548747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let us imagine that you are doing a search on below documents with the following query: **life learning**\n",
    "\n",
    "* **Document 1** : I want to start learning to charge something in life.\n",
    "* **Document 2** : learning something about me no one else knows\n",
    "* **Document 3** : Never stop learning\n",
    "\n",
    "The query is a free text query. It means a query in which the terms of the query are typed freeform into the search interface, without any connecting search operators.\n",
    "\n",
    "Let us go over each step in detail to see how it all works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015949,
     "end_time": "2021-03-10T09:03:36.593749",
     "exception": false,
     "start_time": "2021-03-10T09:03:36.577800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1.Term Frequency(TF)\n",
    "Term Frequency also known as TF measures the number of times a term (word) occurs in a document. Given below is the code and the terms and their frequency on each of the document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprting required libraries\n",
    "# math for mathematical operations\n",
    "# numpy and pandas for data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T09:03:36.628257Z",
     "iopub.status.busy": "2021-03-10T09:03:36.627574Z",
     "iopub.status.idle": "2021-03-10T09:03:36.630522Z",
     "shell.execute_reply": "2021-03-10T09:03:36.629964Z"
    },
    "papermill": {
     "duration": 0.022235,
     "end_time": "2021-03-10T09:03:36.630683",
     "exception": false,
     "start_time": "2021-03-10T09:03:36.608448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading the ted_main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Sir Ken Robinson makes an entertaining and pro...\n",
       "1    With the same humor and humanity he exuded in ...\n",
       "2    New York Times columnist David Pogue takes aim...\n",
       "3    In an emotionally charged talk, MacArthur-winn...\n",
       "4    You've never seen data presented like this. Wi...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('ted_main.csv')\n",
    "dataset['description'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "documents = dataset['description'].head(10).tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sir Ken Robinson makes an entertaining and profoundly moving case for creating an education system that nurtures (rather than undermines) creativity.',\n",
       " 'With the same humor and humanity he exuded in \"An Inconvenient Truth,\" Al Gore spells out 15 ways that individuals can address climate change immediately, from buying a hybrid to inventing a new, hotter brand name for global warming.',\n",
       " 'New York Times columnist David Pogue takes aim at technology’s worst interface-design offenders, and provides encouraging examples of products that get it right. To funny things up, he bursts into song.',\n",
       " 'In an emotionally charged talk, MacArthur-winning activist Majora Carter details her fight for environmental justice in the South Bronx -- and shows how minority neighborhoods suffer most from flawed urban policy.',\n",
       " 'You\\'ve never seen data presented like this. With the drama and urgency of a sportscaster, statistics guru Hans Rosling debunks myths about the so-called \"developing world.\"',\n",
       " 'Tony Robbins discusses the \"invisible forces\" that motivate everyone\\'s actions -- and high-fives Al Gore in the front row.',\n",
       " 'When two young Mormon missionaries knock on Julia Sweeney\\'s door one day, it touches off a quest to completely rethink her own beliefs, in this excerpt from Sweeney\\'s solo show \"Letting Go of God.\"  ',\n",
       " 'Architect Joshua Prince-Ramus takes the audience on dazzling, dizzying virtual tours of three recent projects: the Central Library in Seattle, the Museum Plaza in Louisville and the Charles Wyly Theater in Dallas.',\n",
       " 'Philosopher Dan Dennett calls for religion -- all religion -- to be taught in schools, so we can understand its nature as a natural phenomenon. Then he takes on The Purpose-Driven Life, disputing its claim that, to be moral, one must deny evolution.',\n",
       " 'Pastor Rick Warren, author of \"The Purpose-Driven Life,\" reflects on his own crisis of purpose in the wake of his book\\'s wild success. He explains his belief that God\\'s intention is for each of us to use our talents and influence to do good.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries\n",
    "- We have specified three queries and for each query the rest of the queries can be commneted and the program can be used to compute the probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"the presented data dazzles how politics has changed in recent years\"\n",
    "# query = \"science fiction movies emotionally charged the audience\"\n",
    "query = \"humanity and humor earn more than half of the population by New York Times\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01451,
     "end_time": "2021-03-10T09:03:36.699155",
     "exception": false,
     "start_time": "2021-03-10T09:03:36.684645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**NOTE :** Text Preprocessing Steps are ignored as the objective of this kernel is to explain and develop TF-IDF and cosine similarity from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T09:03:36.739146Z",
     "iopub.status.busy": "2021-03-10T09:03:36.738408Z",
     "iopub.status.idle": "2021-03-10T09:03:36.769276Z",
     "shell.execute_reply": "2021-03-10T09:03:36.769779Z"
    },
    "papermill": {
     "duration": 0.055228,
     "end_time": "2021-03-10T09:03:36.769940",
     "exception": false,
     "start_time": "2021-03-10T09:03:36.714712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Document  undermines)  profoundly  nurtures  entertaining  education  \\\n",
      "0  Term Frequency            1           1         1             1          1   \n",
      "\n",
      "   Sir  system  Ken  for  (rather  than  creating  makes  case  and  Robinson  \\\n",
      "0    1       1    1    1        1     1         1      1     1    1         1   \n",
      "\n",
      "   moving  an  that  creativity.  \n",
      "0       1   2     1            1  \n",
      "         Document  to  exuded  new,  address  immediately,  buying  in  can  \\\n",
      "0  Term Frequency   1       1     1        1             1       1   1    1   \n",
      "\n",
      "   warming.  With  ways  out  hybrid  same  for  Inconvenient  global  hotter  \\\n",
      "0         1     1     1    1       1     1    1             1       1       1   \n",
      "\n",
      "   15  \"An  Al  individuals  climate  he  Gore  brand  humor  and  inventing  \\\n",
      "0   1    1   1            1        1   1     1      1      1    1          1   \n",
      "\n",
      "   name  a  spells  from  humanity  change  that  the  Truth,\"  \n",
      "0     1  2       1     1         1       1     1    1        1  \n",
      "         Document  examples  up,  takes  encouraging  of  columnist  \\\n",
      "0  Term Frequency         1    1      1            1   1          1   \n",
      "\n",
      "   technology’s  get  New  products  David  it  To  York  he  provides  at  \\\n",
      "0             1    1    1         1      1   1   1     1   1         1   1   \n",
      "\n",
      "   into  things  song.  and  right.  interface-design  offenders,  Times  aim  \\\n",
      "0     1       1      1    1       1                 1           1      1    1   \n",
      "\n",
      "   that  funny  worst  Pogue  bursts  \n",
      "0     1      1      1      1       1  \n",
      "         Document  flawed  Carter  in  details  neighborhoods  In  for  \\\n",
      "0  Term Frequency       1       1   1        1              1   1    1   \n",
      "\n",
      "   environmental  MacArthur-winning  most  activist  Majora  justice  South  \\\n",
      "0              1                  1     1         1       1        1      1   \n",
      "\n",
      "   how  emotionally  charged  suffer  minority  shows  and  talk,  --  an  \\\n",
      "0    1            1        1       1         1      1    1      1   1   1   \n",
      "\n",
      "   from  Bronx  fight  policy.  urban  the  her  \n",
      "0     1      1      1        1      1    1    1  \n",
      "         Document  myths  You've  of  With  Rosling  like  world.\"  \\\n",
      "0  Term Frequency      1       1   1     1        1     1        1   \n",
      "\n",
      "   sportscaster,  statistics  seen  never  this.  data  presented  about  \\\n",
      "0              1           1     1      1      1     1          1      1   \n",
      "\n",
      "   \"developing  Hans  urgency  guru  debunks  and  a  drama  so-called  the  \n",
      "0            1     1        1     1        1    1  1      1          1    2  \n",
      "         Document  row.  Al  \"invisible  front  discusses  everyone's  \\\n",
      "0  Term Frequency     1   1           1      1          1           1   \n",
      "\n",
      "   actions  --  Robbins  high-fives  that  motivate  forces\"  Gore  in  Tony  \\\n",
      "0        1   1        1           1     1         1        1     1   1     1   \n",
      "\n",
      "   the  and  \n",
      "0    2    1  \n",
      "         Document  to     Go  \"Letting  excerpt  Sweeney's  of  When  door  \\\n",
      "0  Term Frequency   1  2   1         1        1          2   1     1     1   \n",
      "\n",
      "   touches  in  rethink  Julia  it  one  God.\"  completely  day,  \\\n",
      "0        1   1        1      1   1    1      1           1     1   \n",
      "\n",
      "   missionaries  show  this  beliefs,  solo  two  young  a  Mormon  off  \\\n",
      "0             1     1     1         1     1    1      1  1       1    1   \n",
      "\n",
      "   quest  own  from  on  knock  her  \n",
      "0      1    1     1   1      1    1  \n",
      "         Document  takes  dizzying  of  Central  Wyly  in  dazzling,  Theater  \\\n",
      "0  Term Frequency      1         1   1        1     1   3          1        1   \n",
      "\n",
      "   Prince-Ramus  three  Charles  Dallas.  Library  Architect  Plaza  virtual  \\\n",
      "0             1      1        1        1        1          1      1        1   \n",
      "\n",
      "   audience  Seattle,  projects:  and  Louisville  on  Museum  the  recent  \\\n",
      "0         1         1          1    1           1   1       1    4       1   \n",
      "\n",
      "   tours  Joshua  \n",
      "0      1       1  \n",
      "         Document  to  we  moral,  understand  Purpose-Driven  takes  that,  \\\n",
      "0  Term Frequency   2   1       1           1               1      1      1   \n",
      "\n",
      "   in  can  must  evolution.  as  Philosopher  for  one  so  natural  Then  \\\n",
      "0   1    1     1           1   1            1    1    1   1        1     1   \n",
      "\n",
      "   Life,  be  religion  he  schools,  its  Dennett  claim  nature  \\\n",
      "0      1   2         2   1         1    2        1      1       1   \n",
      "\n",
      "   phenomenon.  Dan  --  a  deny  The  disputing  all  on  calls  taught  \n",
      "0            1    1   2  1     1    1          1    1   1      1       1  \n",
      "         Document  to  Purpose-Driven  Rick  our  of  in  success.  \"The  \\\n",
      "0  Term Frequency   2               1     1    1   4   1         1     1   \n",
      "\n",
      "   wild  wake  crisis  reflects  Life,\"  book's  for  each  God's  Pastor  \\\n",
      "0     1     1       1         1       1       1    1     1      1       1   \n",
      "\n",
      "   intention  talents  good.  purpose  do  use  his  explains  and  belief  \\\n",
      "0          1        1      1        1   1    1    3         1    1       1   \n",
      "\n",
      "   influence  Warren,  us  own  is  that  on  the  He  author  \n",
      "0          1        1   1    1   1     1   1    1   1       1  \n"
     ]
    }
   ],
   "source": [
    "#term -frequenvy :word occurences in a document\n",
    "def compute_tf(docs_list):\n",
    "    for doc in docs_list:\n",
    "        doc1_lst = doc.split(\" \")\n",
    "        wordDict_1= dict.fromkeys(set(doc1_lst), 0)\n",
    "\n",
    "        for token in doc1_lst:\n",
    "            wordDict_1[token] +=  1\n",
    "        df = pd.DataFrame([wordDict_1])\n",
    "        idx = 0\n",
    "        new_col = [\"Term Frequency\"]    \n",
    "        df.insert(loc=idx, column='Document', value=new_col)\n",
    "        print(df)\n",
    "        \n",
    "compute_tf(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015216,
     "end_time": "2021-03-10T09:03:36.801004",
     "exception": false,
     "start_time": "2021-03-10T09:03:36.785788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* In reality each document will be of different size. On a large document the frequency of the terms will be much higher than the smaller ones. Hence we need to normalize the document based on its size. \n",
    "* A simple trick is to divide the term frequency by the total number of terms. \n",
    "* For example in Document 1 the term game occurs two times. The total number of terms in the document is 10. Hence the normalized term frequency is 2 / 10 = 0.2. \n",
    "\n",
    "\n",
    "Given below are the normalized term frequency for all the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T09:03:36.854003Z",
     "iopub.status.busy": "2021-03-10T09:03:36.848780Z",
     "iopub.status.idle": "2021-03-10T09:03:36.862977Z",
     "shell.execute_reply": "2021-03-10T09:03:36.862198Z"
    },
    "papermill": {
     "duration": 0.046729,
     "end_time": "2021-03-10T09:03:36.863140",
     "exception": false,
     "start_time": "2021-03-10T09:03:36.816411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Document  undermines)  profoundly  nurtures  entertaining  education  \\\n",
      "0  Normalized TF     0.047619    0.047619  0.047619      0.047619   0.047619   \n",
      "\n",
      "        Sir    system       Ken       for   (rather      than  creating  \\\n",
      "0  0.047619  0.047619  0.047619  0.047619  0.047619  0.047619  0.047619   \n",
      "\n",
      "      makes      case       and  Robinson    moving        an      that  \\\n",
      "0  0.047619  0.047619  0.047619  0.047619  0.047619  0.095238  0.047619   \n",
      "\n",
      "   creativity.  \n",
      "0     0.047619  \n",
      "        Document        to    exuded      new,   address  immediately,  \\\n",
      "0  Normalized TF  0.025641  0.025641  0.025641  0.025641      0.025641   \n",
      "\n",
      "     buying        in       can  warming.      With      ways       out  \\\n",
      "0  0.025641  0.025641  0.025641  0.025641  0.025641  0.025641  0.025641   \n",
      "\n",
      "     hybrid      same       for  Inconvenient    global    hotter        15  \\\n",
      "0  0.025641  0.025641  0.025641      0.025641  0.025641  0.025641  0.025641   \n",
      "\n",
      "        \"An        Al  individuals   climate        he      Gore     brand  \\\n",
      "0  0.025641  0.025641     0.025641  0.025641  0.025641  0.025641  0.025641   \n",
      "\n",
      "      humor       and  inventing      name         a    spells      from  \\\n",
      "0  0.025641  0.025641   0.025641  0.025641  0.051282  0.025641  0.025641   \n",
      "\n",
      "   humanity    change      that       the   Truth,\"  \n",
      "0  0.025641  0.025641  0.025641  0.025641  0.025641  \n",
      "        Document  examples       up,     takes  encouraging        of  \\\n",
      "0  Normalized TF  0.032258  0.032258  0.032258     0.032258  0.032258   \n",
      "\n",
      "   columnist  technology’s       get       New  products     David        it  \\\n",
      "0   0.032258      0.032258  0.032258  0.032258  0.032258  0.032258  0.032258   \n",
      "\n",
      "         To      York        he  provides        at      into    things  \\\n",
      "0  0.032258  0.032258  0.032258  0.032258  0.032258  0.032258  0.032258   \n",
      "\n",
      "      song.       and    right.  interface-design  offenders,     Times  \\\n",
      "0  0.032258  0.032258  0.032258          0.032258    0.032258  0.032258   \n",
      "\n",
      "        aim      that     funny     worst     Pogue    bursts  \n",
      "0  0.032258  0.032258  0.032258  0.032258  0.032258  0.032258  \n",
      "        Document    flawed    Carter        in   details  neighborhoods  \\\n",
      "0  Normalized TF  0.032258  0.032258  0.064516  0.032258       0.032258   \n",
      "\n",
      "         In       for  environmental  MacArthur-winning      most  activist  \\\n",
      "0  0.064516  0.032258       0.032258           0.032258  0.032258  0.032258   \n",
      "\n",
      "     Majora   justice     South       how  emotionally   charged    suffer  \\\n",
      "0  0.032258  0.032258  0.032258  0.032258     0.032258  0.032258  0.032258   \n",
      "\n",
      "   minority     shows       and     talk,        --        an      from  \\\n",
      "0  0.032258  0.032258  0.032258  0.032258  0.032258  0.032258  0.032258   \n",
      "\n",
      "      Bronx     fight   policy.     urban       the       her  \n",
      "0  0.032258  0.032258  0.032258  0.032258  0.032258  0.032258  \n",
      "        Document     myths    You've        of      With   Rosling      like  \\\n",
      "0  Normalized TF  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462   \n",
      "\n",
      "    world.\"  sportscaster,  statistics      seen     never     this.  \\\n",
      "0  0.038462       0.038462    0.038462  0.038462  0.038462  0.038462   \n",
      "\n",
      "       data  presented     about  \"developing      Hans   urgency      guru  \\\n",
      "0  0.038462   0.038462  0.038462     0.038462  0.038462  0.038462  0.038462   \n",
      "\n",
      "    debunks       and         a     drama  so-called       the  \n",
      "0  0.038462  0.038462  0.038462  0.038462   0.038462  0.076923  \n",
      "        Document      row.        Al  \"invisible     front  discusses  \\\n",
      "0  Normalized TF  0.052632  0.052632    0.052632  0.052632   0.052632   \n",
      "\n",
      "   everyone's   actions        --   Robbins  high-fives      that  motivate  \\\n",
      "0    0.052632  0.052632  0.052632  0.052632    0.052632  0.052632  0.052632   \n",
      "\n",
      "    forces\"      Gore        in      Tony       the       and  \n",
      "0  0.052632  0.052632  0.052632  0.052632  0.105263  0.052632  \n",
      "        Document        to        Go  \"Letting   excerpt  Sweeney's        of  \\\n",
      "0  Normalized TF  0.029412  0.029412  0.029412  0.029412   0.058824  0.029412   \n",
      "\n",
      "       When      door   touches        in   rethink     Julia        it  \\\n",
      "0  0.029412  0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
      "\n",
      "        one     God.\"  completely      day,  missionaries      show      this  \\\n",
      "0  0.029412  0.029412    0.029412  0.029412      0.029412  0.029412  0.029412   \n",
      "\n",
      "   beliefs,      solo       two     young         a    Mormon       off  \\\n",
      "0  0.029412  0.029412  0.029412  0.029412  0.029412  0.029412  0.029412   \n",
      "\n",
      "      quest       own      from        on     knock       her  \n",
      "0  0.029412  0.029412  0.029412  0.029412  0.029412  0.029412  \n",
      "        Document    takes  dizzying       of  Central     Wyly       in  \\\n",
      "0  Normalized TF  0.03125   0.03125  0.03125  0.03125  0.03125  0.09375   \n",
      "\n",
      "   dazzling,  Theater  Prince-Ramus    three  Charles  Dallas.  Library  \\\n",
      "0    0.03125  0.03125       0.03125  0.03125  0.03125  0.03125  0.03125   \n",
      "\n",
      "   Architect    Plaza  virtual  audience  Seattle,  projects:      and  \\\n",
      "0    0.03125  0.03125  0.03125   0.03125   0.03125    0.03125  0.03125   \n",
      "\n",
      "   Louisville       on   Museum    the   recent    tours   Joshua  \n",
      "0     0.03125  0.03125  0.03125  0.125  0.03125  0.03125  0.03125  \n",
      "        Document        to        we    moral,  understand  Purpose-Driven  \\\n",
      "0  Normalized TF  0.046512  0.023256  0.023256    0.023256        0.023256   \n",
      "\n",
      "      takes     that,        in       can      must  evolution.        as  \\\n",
      "0  0.023256  0.023256  0.023256  0.023256  0.023256    0.023256  0.023256   \n",
      "\n",
      "   Philosopher       for       one        so   natural      Then     Life,  \\\n",
      "0     0.023256  0.023256  0.023256  0.023256  0.023256  0.023256  0.023256   \n",
      "\n",
      "         be  religion        he  schools,       its   Dennett     claim  \\\n",
      "0  0.046512  0.046512  0.023256  0.023256  0.046512  0.023256  0.023256   \n",
      "\n",
      "     nature  phenomenon.       Dan        --         a      deny       The  \\\n",
      "0  0.023256     0.023256  0.023256  0.046512  0.023256  0.023256  0.023256   \n",
      "\n",
      "   disputing       all        on     calls    taught  \n",
      "0   0.023256  0.023256  0.023256  0.023256  0.023256  \n",
      "        Document        to  Purpose-Driven      Rick       our        of  \\\n",
      "0  Normalized TF  0.045455        0.022727  0.022727  0.022727  0.090909   \n",
      "\n",
      "         in  success.      \"The      wild      wake    crisis  reflects  \\\n",
      "0  0.022727  0.022727  0.022727  0.022727  0.022727  0.022727  0.022727   \n",
      "\n",
      "     Life,\"    book's       for      each     God's    Pastor  intention  \\\n",
      "0  0.022727  0.022727  0.022727  0.022727  0.022727  0.022727   0.022727   \n",
      "\n",
      "    talents     good.   purpose        do       use       his  explains  \\\n",
      "0  0.022727  0.022727  0.022727  0.022727  0.022727  0.068182  0.022727   \n",
      "\n",
      "        and    belief  influence   Warren,        us       own        is  \\\n",
      "0  0.022727  0.022727   0.022727  0.022727  0.022727  0.022727  0.022727   \n",
      "\n",
      "       that        on       the        He    author  \n",
      "0  0.022727  0.022727  0.022727  0.022727  0.022727  \n"
     ]
    }
   ],
   "source": [
    "#Normalized Term Frequency\n",
    "def termFrequency(term, document):\n",
    "    normalizeDocument = document.lower().split()\n",
    "    return normalizeDocument.count(term.lower()) / float(len(normalizeDocument))\n",
    "\n",
    "def compute_normalizedtf(documents):\n",
    "    tf_doc = []\n",
    "    for txt in documents:\n",
    "        sentence = txt.split()\n",
    "        norm_tf= dict.fromkeys(set(sentence), 0)\n",
    "        for word in sentence:\n",
    "            norm_tf[word] = termFrequency(word, txt)\n",
    "        tf_doc.append(norm_tf)\n",
    "        df = pd.DataFrame([norm_tf])\n",
    "        idx = 0\n",
    "        new_col = [\"Normalized TF\"]    \n",
    "        df.insert(loc=idx, column='Document', value=new_col)\n",
    "        print(df)\n",
    "    return tf_doc\n",
    "\n",
    "tf_doc = compute_normalizedtf(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'undermines)': 0.047619047619047616,\n",
       "  'profoundly': 0.047619047619047616,\n",
       "  'nurtures': 0.047619047619047616,\n",
       "  'entertaining': 0.047619047619047616,\n",
       "  'education': 0.047619047619047616,\n",
       "  'Sir': 0.047619047619047616,\n",
       "  'system': 0.047619047619047616,\n",
       "  'Ken': 0.047619047619047616,\n",
       "  'for': 0.047619047619047616,\n",
       "  '(rather': 0.047619047619047616,\n",
       "  'than': 0.047619047619047616,\n",
       "  'creating': 0.047619047619047616,\n",
       "  'makes': 0.047619047619047616,\n",
       "  'case': 0.047619047619047616,\n",
       "  'and': 0.047619047619047616,\n",
       "  'Robinson': 0.047619047619047616,\n",
       "  'moving': 0.047619047619047616,\n",
       "  'an': 0.09523809523809523,\n",
       "  'that': 0.047619047619047616,\n",
       "  'creativity.': 0.047619047619047616},\n",
       " {'to': 0.02564102564102564,\n",
       "  'exuded': 0.02564102564102564,\n",
       "  'new,': 0.02564102564102564,\n",
       "  'address': 0.02564102564102564,\n",
       "  'immediately,': 0.02564102564102564,\n",
       "  'buying': 0.02564102564102564,\n",
       "  'in': 0.02564102564102564,\n",
       "  'can': 0.02564102564102564,\n",
       "  'warming.': 0.02564102564102564,\n",
       "  'With': 0.02564102564102564,\n",
       "  'ways': 0.02564102564102564,\n",
       "  'out': 0.02564102564102564,\n",
       "  'hybrid': 0.02564102564102564,\n",
       "  'same': 0.02564102564102564,\n",
       "  'for': 0.02564102564102564,\n",
       "  'Inconvenient': 0.02564102564102564,\n",
       "  'global': 0.02564102564102564,\n",
       "  'hotter': 0.02564102564102564,\n",
       "  '15': 0.02564102564102564,\n",
       "  '\"An': 0.02564102564102564,\n",
       "  'Al': 0.02564102564102564,\n",
       "  'individuals': 0.02564102564102564,\n",
       "  'climate': 0.02564102564102564,\n",
       "  'he': 0.02564102564102564,\n",
       "  'Gore': 0.02564102564102564,\n",
       "  'brand': 0.02564102564102564,\n",
       "  'humor': 0.02564102564102564,\n",
       "  'and': 0.02564102564102564,\n",
       "  'inventing': 0.02564102564102564,\n",
       "  'name': 0.02564102564102564,\n",
       "  'a': 0.05128205128205128,\n",
       "  'spells': 0.02564102564102564,\n",
       "  'from': 0.02564102564102564,\n",
       "  'humanity': 0.02564102564102564,\n",
       "  'change': 0.02564102564102564,\n",
       "  'that': 0.02564102564102564,\n",
       "  'the': 0.02564102564102564,\n",
       "  'Truth,\"': 0.02564102564102564},\n",
       " {'examples': 0.03225806451612903,\n",
       "  'up,': 0.03225806451612903,\n",
       "  'takes': 0.03225806451612903,\n",
       "  'encouraging': 0.03225806451612903,\n",
       "  'of': 0.03225806451612903,\n",
       "  'columnist': 0.03225806451612903,\n",
       "  'technology’s': 0.03225806451612903,\n",
       "  'get': 0.03225806451612903,\n",
       "  'New': 0.03225806451612903,\n",
       "  'products': 0.03225806451612903,\n",
       "  'David': 0.03225806451612903,\n",
       "  'it': 0.03225806451612903,\n",
       "  'To': 0.03225806451612903,\n",
       "  'York': 0.03225806451612903,\n",
       "  'he': 0.03225806451612903,\n",
       "  'provides': 0.03225806451612903,\n",
       "  'at': 0.03225806451612903,\n",
       "  'into': 0.03225806451612903,\n",
       "  'things': 0.03225806451612903,\n",
       "  'song.': 0.03225806451612903,\n",
       "  'and': 0.03225806451612903,\n",
       "  'right.': 0.03225806451612903,\n",
       "  'interface-design': 0.03225806451612903,\n",
       "  'offenders,': 0.03225806451612903,\n",
       "  'Times': 0.03225806451612903,\n",
       "  'aim': 0.03225806451612903,\n",
       "  'that': 0.03225806451612903,\n",
       "  'funny': 0.03225806451612903,\n",
       "  'worst': 0.03225806451612903,\n",
       "  'Pogue': 0.03225806451612903,\n",
       "  'bursts': 0.03225806451612903},\n",
       " {'flawed': 0.03225806451612903,\n",
       "  'Carter': 0.03225806451612903,\n",
       "  'in': 0.06451612903225806,\n",
       "  'details': 0.03225806451612903,\n",
       "  'neighborhoods': 0.03225806451612903,\n",
       "  'In': 0.06451612903225806,\n",
       "  'for': 0.03225806451612903,\n",
       "  'environmental': 0.03225806451612903,\n",
       "  'MacArthur-winning': 0.03225806451612903,\n",
       "  'most': 0.03225806451612903,\n",
       "  'activist': 0.03225806451612903,\n",
       "  'Majora': 0.03225806451612903,\n",
       "  'justice': 0.03225806451612903,\n",
       "  'South': 0.03225806451612903,\n",
       "  'how': 0.03225806451612903,\n",
       "  'emotionally': 0.03225806451612903,\n",
       "  'charged': 0.03225806451612903,\n",
       "  'suffer': 0.03225806451612903,\n",
       "  'minority': 0.03225806451612903,\n",
       "  'shows': 0.03225806451612903,\n",
       "  'and': 0.03225806451612903,\n",
       "  'talk,': 0.03225806451612903,\n",
       "  '--': 0.03225806451612903,\n",
       "  'an': 0.03225806451612903,\n",
       "  'from': 0.03225806451612903,\n",
       "  'Bronx': 0.03225806451612903,\n",
       "  'fight': 0.03225806451612903,\n",
       "  'policy.': 0.03225806451612903,\n",
       "  'urban': 0.03225806451612903,\n",
       "  'the': 0.03225806451612903,\n",
       "  'her': 0.03225806451612903},\n",
       " {'myths': 0.038461538461538464,\n",
       "  \"You've\": 0.038461538461538464,\n",
       "  'of': 0.038461538461538464,\n",
       "  'With': 0.038461538461538464,\n",
       "  'Rosling': 0.038461538461538464,\n",
       "  'like': 0.038461538461538464,\n",
       "  'world.\"': 0.038461538461538464,\n",
       "  'sportscaster,': 0.038461538461538464,\n",
       "  'statistics': 0.038461538461538464,\n",
       "  'seen': 0.038461538461538464,\n",
       "  'never': 0.038461538461538464,\n",
       "  'this.': 0.038461538461538464,\n",
       "  'data': 0.038461538461538464,\n",
       "  'presented': 0.038461538461538464,\n",
       "  'about': 0.038461538461538464,\n",
       "  '\"developing': 0.038461538461538464,\n",
       "  'Hans': 0.038461538461538464,\n",
       "  'urgency': 0.038461538461538464,\n",
       "  'guru': 0.038461538461538464,\n",
       "  'debunks': 0.038461538461538464,\n",
       "  'and': 0.038461538461538464,\n",
       "  'a': 0.038461538461538464,\n",
       "  'drama': 0.038461538461538464,\n",
       "  'so-called': 0.038461538461538464,\n",
       "  'the': 0.07692307692307693},\n",
       " {'row.': 0.05263157894736842,\n",
       "  'Al': 0.05263157894736842,\n",
       "  '\"invisible': 0.05263157894736842,\n",
       "  'front': 0.05263157894736842,\n",
       "  'discusses': 0.05263157894736842,\n",
       "  \"everyone's\": 0.05263157894736842,\n",
       "  'actions': 0.05263157894736842,\n",
       "  '--': 0.05263157894736842,\n",
       "  'Robbins': 0.05263157894736842,\n",
       "  'high-fives': 0.05263157894736842,\n",
       "  'that': 0.05263157894736842,\n",
       "  'motivate': 0.05263157894736842,\n",
       "  'forces\"': 0.05263157894736842,\n",
       "  'Gore': 0.05263157894736842,\n",
       "  'in': 0.05263157894736842,\n",
       "  'Tony': 0.05263157894736842,\n",
       "  'the': 0.10526315789473684,\n",
       "  'and': 0.05263157894736842},\n",
       " {'to': 0.029411764705882353,\n",
       "  'Go': 0.029411764705882353,\n",
       "  '\"Letting': 0.029411764705882353,\n",
       "  'excerpt': 0.029411764705882353,\n",
       "  \"Sweeney's\": 0.058823529411764705,\n",
       "  'of': 0.029411764705882353,\n",
       "  'When': 0.029411764705882353,\n",
       "  'door': 0.029411764705882353,\n",
       "  'touches': 0.029411764705882353,\n",
       "  'in': 0.029411764705882353,\n",
       "  'rethink': 0.029411764705882353,\n",
       "  'Julia': 0.029411764705882353,\n",
       "  'it': 0.029411764705882353,\n",
       "  'one': 0.029411764705882353,\n",
       "  'God.\"': 0.029411764705882353,\n",
       "  'completely': 0.029411764705882353,\n",
       "  'day,': 0.029411764705882353,\n",
       "  'missionaries': 0.029411764705882353,\n",
       "  'show': 0.029411764705882353,\n",
       "  'this': 0.029411764705882353,\n",
       "  'beliefs,': 0.029411764705882353,\n",
       "  'solo': 0.029411764705882353,\n",
       "  'two': 0.029411764705882353,\n",
       "  'young': 0.029411764705882353,\n",
       "  'a': 0.029411764705882353,\n",
       "  'Mormon': 0.029411764705882353,\n",
       "  'off': 0.029411764705882353,\n",
       "  'quest': 0.029411764705882353,\n",
       "  'own': 0.029411764705882353,\n",
       "  'from': 0.029411764705882353,\n",
       "  'on': 0.029411764705882353,\n",
       "  'knock': 0.029411764705882353,\n",
       "  'her': 0.029411764705882353},\n",
       " {'takes': 0.03125,\n",
       "  'dizzying': 0.03125,\n",
       "  'of': 0.03125,\n",
       "  'Central': 0.03125,\n",
       "  'Wyly': 0.03125,\n",
       "  'in': 0.09375,\n",
       "  'dazzling,': 0.03125,\n",
       "  'Theater': 0.03125,\n",
       "  'Prince-Ramus': 0.03125,\n",
       "  'three': 0.03125,\n",
       "  'Charles': 0.03125,\n",
       "  'Dallas.': 0.03125,\n",
       "  'Library': 0.03125,\n",
       "  'Architect': 0.03125,\n",
       "  'Plaza': 0.03125,\n",
       "  'virtual': 0.03125,\n",
       "  'audience': 0.03125,\n",
       "  'Seattle,': 0.03125,\n",
       "  'projects:': 0.03125,\n",
       "  'and': 0.03125,\n",
       "  'Louisville': 0.03125,\n",
       "  'on': 0.03125,\n",
       "  'Museum': 0.03125,\n",
       "  'the': 0.125,\n",
       "  'recent': 0.03125,\n",
       "  'tours': 0.03125,\n",
       "  'Joshua': 0.03125},\n",
       " {'to': 0.046511627906976744,\n",
       "  'we': 0.023255813953488372,\n",
       "  'moral,': 0.023255813953488372,\n",
       "  'understand': 0.023255813953488372,\n",
       "  'Purpose-Driven': 0.023255813953488372,\n",
       "  'takes': 0.023255813953488372,\n",
       "  'that,': 0.023255813953488372,\n",
       "  'in': 0.023255813953488372,\n",
       "  'can': 0.023255813953488372,\n",
       "  'must': 0.023255813953488372,\n",
       "  'evolution.': 0.023255813953488372,\n",
       "  'as': 0.023255813953488372,\n",
       "  'Philosopher': 0.023255813953488372,\n",
       "  'for': 0.023255813953488372,\n",
       "  'one': 0.023255813953488372,\n",
       "  'so': 0.023255813953488372,\n",
       "  'natural': 0.023255813953488372,\n",
       "  'Then': 0.023255813953488372,\n",
       "  'Life,': 0.023255813953488372,\n",
       "  'be': 0.046511627906976744,\n",
       "  'religion': 0.046511627906976744,\n",
       "  'he': 0.023255813953488372,\n",
       "  'schools,': 0.023255813953488372,\n",
       "  'its': 0.046511627906976744,\n",
       "  'Dennett': 0.023255813953488372,\n",
       "  'claim': 0.023255813953488372,\n",
       "  'nature': 0.023255813953488372,\n",
       "  'phenomenon.': 0.023255813953488372,\n",
       "  'Dan': 0.023255813953488372,\n",
       "  '--': 0.046511627906976744,\n",
       "  'a': 0.023255813953488372,\n",
       "  'deny': 0.023255813953488372,\n",
       "  'The': 0.023255813953488372,\n",
       "  'disputing': 0.023255813953488372,\n",
       "  'all': 0.023255813953488372,\n",
       "  'on': 0.023255813953488372,\n",
       "  'calls': 0.023255813953488372,\n",
       "  'taught': 0.023255813953488372},\n",
       " {'to': 0.045454545454545456,\n",
       "  'Purpose-Driven': 0.022727272727272728,\n",
       "  'Rick': 0.022727272727272728,\n",
       "  'our': 0.022727272727272728,\n",
       "  'of': 0.09090909090909091,\n",
       "  'in': 0.022727272727272728,\n",
       "  'success.': 0.022727272727272728,\n",
       "  '\"The': 0.022727272727272728,\n",
       "  'wild': 0.022727272727272728,\n",
       "  'wake': 0.022727272727272728,\n",
       "  'crisis': 0.022727272727272728,\n",
       "  'reflects': 0.022727272727272728,\n",
       "  'Life,\"': 0.022727272727272728,\n",
       "  \"book's\": 0.022727272727272728,\n",
       "  'for': 0.022727272727272728,\n",
       "  'each': 0.022727272727272728,\n",
       "  \"God's\": 0.022727272727272728,\n",
       "  'Pastor': 0.022727272727272728,\n",
       "  'intention': 0.022727272727272728,\n",
       "  'talents': 0.022727272727272728,\n",
       "  'good.': 0.022727272727272728,\n",
       "  'purpose': 0.022727272727272728,\n",
       "  'do': 0.022727272727272728,\n",
       "  'use': 0.022727272727272728,\n",
       "  'his': 0.06818181818181818,\n",
       "  'explains': 0.022727272727272728,\n",
       "  'and': 0.022727272727272728,\n",
       "  'belief': 0.022727272727272728,\n",
       "  'influence': 0.022727272727272728,\n",
       "  'Warren,': 0.022727272727272728,\n",
       "  'us': 0.022727272727272728,\n",
       "  'own': 0.022727272727272728,\n",
       "  'is': 0.022727272727272728,\n",
       "  'that': 0.022727272727272728,\n",
       "  'on': 0.022727272727272728,\n",
       "  'the': 0.022727272727272728,\n",
       "  'He': 0.022727272727272728,\n",
       "  'author': 0.022727272727272728}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016057,
     "end_time": "2021-03-10T09:03:36.895610",
     "exception": false,
     "start_time": "2021-03-10T09:03:36.879553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Inverse Document Frequency (IDF)\n",
    "\n",
    "* The main purpose of doing a search is to find out relevant documents matching the query. \n",
    "* In Term Frequecy all terms are considered equally important. In fact certain terms that occur too frequently have little power in determining the relevance. \n",
    "* We need a way to weigh down the effects of too frequently occurring terms. Also the terms that occur less in the document can be more relevant. \n",
    "* We need a way to weigh up the effects of less frequently occurring terms. Logarithms helps us to solve this problem.Logarithms helps us to solve this problem.\n",
    "\n",
    "\n",
    "Let us compute IDF for the term start\n",
    "\n",
    "IDF(start) = 1 + loge(Total Number Of Documents / Number Of Documents with term start in it)\n",
    "\n",
    "There are 3 documents in all = Document1, Document2, Document3\n",
    "The term start appears in Document1\n",
    "\n",
    " IDF(start) = 1 + loge(3 / 1)\n",
    "            = 1 + 1.098726209\n",
    "            = 2.098726209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T09:03:36.942741Z",
     "iopub.status.busy": "2021-03-10T09:03:36.942030Z",
     "iopub.status.idle": "2021-03-10T09:03:36.946998Z",
     "shell.execute_reply": "2021-03-10T09:03:36.946265Z"
    },
    "papermill": {
     "duration": 0.03524,
     "end_time": "2021-03-10T09:03:36.947120",
     "exception": false,
     "start_time": "2021-03-10T09:03:36.911880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sir': 3.302585092994046,\n",
       " 'Ken': 3.302585092994046,\n",
       " 'Robinson': 3.302585092994046,\n",
       " 'makes': 3.302585092994046,\n",
       " 'an': 2.6094379124341005,\n",
       " 'entertaining': 3.302585092994046,\n",
       " 'and': 1.2231435513142097,\n",
       " 'profoundly': 3.302585092994046,\n",
       " 'moving': 3.302585092994046,\n",
       " 'case': 3.302585092994046,\n",
       " 'for': 1.6931471805599454,\n",
       " 'creating': 3.302585092994046,\n",
       " 'education': 3.302585092994046,\n",
       " 'system': 3.302585092994046,\n",
       " 'that': 1.6931471805599454,\n",
       " 'nurtures': 3.302585092994046,\n",
       " '(rather': 3.302585092994046,\n",
       " 'than': 3.302585092994046,\n",
       " 'undermines)': 3.302585092994046,\n",
       " 'creativity.': 3.302585092994046,\n",
       " 'With': 2.6094379124341005,\n",
       " 'the': 1.3566749439387324,\n",
       " 'same': 3.302585092994046,\n",
       " 'humor': 3.302585092994046,\n",
       " 'humanity': 3.302585092994046,\n",
       " 'he': 1.916290731874155,\n",
       " 'exuded': 3.302585092994046,\n",
       " 'in': 1.3566749439387324,\n",
       " '\"An': 3.302585092994046,\n",
       " 'Inconvenient': 3.302585092994046,\n",
       " 'Truth,\"': 3.302585092994046,\n",
       " 'Al': 2.6094379124341005,\n",
       " 'Gore': 2.6094379124341005,\n",
       " 'spells': 3.302585092994046,\n",
       " 'out': 3.302585092994046,\n",
       " '15': 3.302585092994046,\n",
       " 'ways': 3.302585092994046,\n",
       " 'individuals': 3.302585092994046,\n",
       " 'can': 2.6094379124341005,\n",
       " 'address': 3.302585092994046,\n",
       " 'climate': 3.302585092994046,\n",
       " 'change': 3.302585092994046,\n",
       " 'immediately,': 3.302585092994046,\n",
       " 'from': 2.203972804325936,\n",
       " 'buying': 3.302585092994046,\n",
       " 'a': 1.916290731874155,\n",
       " 'hybrid': 3.302585092994046,\n",
       " 'to': 1.6931471805599454,\n",
       " 'inventing': 3.302585092994046,\n",
       " 'new,': 3.302585092994046,\n",
       " 'hotter': 3.302585092994046,\n",
       " 'brand': 3.302585092994046,\n",
       " 'name': 3.302585092994046,\n",
       " 'global': 3.302585092994046,\n",
       " 'warming.': 3.302585092994046,\n",
       " 'New': 3.302585092994046,\n",
       " 'York': 3.302585092994046,\n",
       " 'Times': 3.302585092994046,\n",
       " 'columnist': 3.302585092994046,\n",
       " 'David': 3.302585092994046,\n",
       " 'Pogue': 3.302585092994046,\n",
       " 'takes': 2.203972804325936,\n",
       " 'aim': 3.302585092994046,\n",
       " 'at': 3.302585092994046,\n",
       " 'technology’s': 3.302585092994046,\n",
       " 'worst': 3.302585092994046,\n",
       " 'interface-design': 3.302585092994046,\n",
       " 'offenders,': 3.302585092994046,\n",
       " 'provides': 3.302585092994046,\n",
       " 'encouraging': 3.302585092994046,\n",
       " 'examples': 3.302585092994046,\n",
       " 'of': 1.6931471805599454,\n",
       " 'products': 3.302585092994046,\n",
       " 'get': 3.302585092994046,\n",
       " 'it': 2.6094379124341005,\n",
       " 'right.': 3.302585092994046,\n",
       " 'To': 1.6931471805599454,\n",
       " 'funny': 3.302585092994046,\n",
       " 'things': 3.302585092994046,\n",
       " 'up,': 3.302585092994046,\n",
       " 'bursts': 3.302585092994046,\n",
       " 'into': 3.302585092994046,\n",
       " 'song.': 3.302585092994046,\n",
       " 'In': 1.3566749439387324,\n",
       " 'emotionally': 3.302585092994046,\n",
       " 'charged': 3.302585092994046,\n",
       " 'talk,': 3.302585092994046,\n",
       " 'MacArthur-winning': 3.302585092994046,\n",
       " 'activist': 3.302585092994046,\n",
       " 'Majora': 3.302585092994046,\n",
       " 'Carter': 3.302585092994046,\n",
       " 'details': 3.302585092994046,\n",
       " 'her': 2.6094379124341005,\n",
       " 'fight': 3.302585092994046,\n",
       " 'environmental': 3.302585092994046,\n",
       " 'justice': 3.302585092994046,\n",
       " 'South': 3.302585092994046,\n",
       " 'Bronx': 3.302585092994046,\n",
       " '--': 2.203972804325936,\n",
       " 'shows': 3.302585092994046,\n",
       " 'how': 3.302585092994046,\n",
       " 'minority': 3.302585092994046,\n",
       " 'neighborhoods': 3.302585092994046,\n",
       " 'suffer': 3.302585092994046,\n",
       " 'most': 3.302585092994046,\n",
       " 'flawed': 3.302585092994046,\n",
       " 'urban': 3.302585092994046,\n",
       " 'policy.': 3.302585092994046,\n",
       " \"You've\": 3.302585092994046,\n",
       " 'never': 3.302585092994046,\n",
       " 'seen': 3.302585092994046,\n",
       " 'data': 3.302585092994046,\n",
       " 'presented': 3.302585092994046,\n",
       " 'like': 3.302585092994046,\n",
       " 'this.': 3.302585092994046,\n",
       " 'drama': 3.302585092994046,\n",
       " 'urgency': 3.302585092994046,\n",
       " 'sportscaster,': 3.302585092994046,\n",
       " 'statistics': 3.302585092994046,\n",
       " 'guru': 3.302585092994046,\n",
       " 'Hans': 3.302585092994046,\n",
       " 'Rosling': 3.302585092994046,\n",
       " 'debunks': 3.302585092994046,\n",
       " 'myths': 3.302585092994046,\n",
       " 'about': 3.302585092994046,\n",
       " 'so-called': 3.302585092994046,\n",
       " '\"developing': 3.302585092994046,\n",
       " 'world.\"': 3.302585092994046,\n",
       " 'Tony': 3.302585092994046,\n",
       " 'Robbins': 3.302585092994046,\n",
       " 'discusses': 3.302585092994046,\n",
       " '\"invisible': 3.302585092994046,\n",
       " 'forces\"': 3.302585092994046,\n",
       " 'motivate': 3.302585092994046,\n",
       " \"everyone's\": 3.302585092994046,\n",
       " 'actions': 3.302585092994046,\n",
       " 'high-fives': 3.302585092994046,\n",
       " 'front': 3.302585092994046,\n",
       " 'row.': 3.302585092994046,\n",
       " 'When': 3.302585092994046,\n",
       " 'two': 3.302585092994046,\n",
       " 'young': 3.302585092994046,\n",
       " 'Mormon': 3.302585092994046,\n",
       " 'missionaries': 3.302585092994046,\n",
       " 'knock': 3.302585092994046,\n",
       " 'on': 1.916290731874155,\n",
       " 'Julia': 3.302585092994046,\n",
       " \"Sweeney's\": 3.302585092994046,\n",
       " 'door': 3.302585092994046,\n",
       " 'one': 2.6094379124341005,\n",
       " 'day,': 3.302585092994046,\n",
       " 'touches': 3.302585092994046,\n",
       " 'off': 3.302585092994046,\n",
       " 'quest': 3.302585092994046,\n",
       " 'completely': 3.302585092994046,\n",
       " 'rethink': 3.302585092994046,\n",
       " 'own': 2.6094379124341005,\n",
       " 'beliefs,': 3.302585092994046,\n",
       " 'this': 3.302585092994046,\n",
       " 'excerpt': 3.302585092994046,\n",
       " 'solo': 3.302585092994046,\n",
       " 'show': 3.302585092994046,\n",
       " '\"Letting': 3.302585092994046,\n",
       " 'Go': 3.302585092994046,\n",
       " 'God.\"': 3.302585092994046,\n",
       " 'Architect': 3.302585092994046,\n",
       " 'Joshua': 3.302585092994046,\n",
       " 'Prince-Ramus': 3.302585092994046,\n",
       " 'audience': 3.302585092994046,\n",
       " 'dazzling,': 3.302585092994046,\n",
       " 'dizzying': 3.302585092994046,\n",
       " 'virtual': 3.302585092994046,\n",
       " 'tours': 3.302585092994046,\n",
       " 'three': 3.302585092994046,\n",
       " 'recent': 3.302585092994046,\n",
       " 'projects:': 3.302585092994046,\n",
       " 'Central': 3.302585092994046,\n",
       " 'Library': 3.302585092994046,\n",
       " 'Seattle,': 3.302585092994046,\n",
       " 'Museum': 3.302585092994046,\n",
       " 'Plaza': 3.302585092994046,\n",
       " 'Louisville': 3.302585092994046,\n",
       " 'Charles': 3.302585092994046,\n",
       " 'Wyly': 3.302585092994046,\n",
       " 'Theater': 3.302585092994046,\n",
       " 'Dallas.': 3.302585092994046,\n",
       " 'Philosopher': 3.302585092994046,\n",
       " 'Dan': 3.302585092994046,\n",
       " 'Dennett': 3.302585092994046,\n",
       " 'calls': 3.302585092994046,\n",
       " 'religion': 3.302585092994046,\n",
       " 'all': 3.302585092994046,\n",
       " 'be': 3.302585092994046,\n",
       " 'taught': 3.302585092994046,\n",
       " 'schools,': 3.302585092994046,\n",
       " 'so': 3.302585092994046,\n",
       " 'we': 3.302585092994046,\n",
       " 'understand': 3.302585092994046,\n",
       " 'its': 3.302585092994046,\n",
       " 'nature': 3.302585092994046,\n",
       " 'as': 3.302585092994046,\n",
       " 'natural': 3.302585092994046,\n",
       " 'phenomenon.': 3.302585092994046,\n",
       " 'Then': 3.302585092994046,\n",
       " 'The': 1.3566749439387324,\n",
       " 'Purpose-Driven': 2.6094379124341005,\n",
       " 'Life,': 3.302585092994046,\n",
       " 'disputing': 3.302585092994046,\n",
       " 'claim': 3.302585092994046,\n",
       " 'that,': 3.302585092994046,\n",
       " 'moral,': 3.302585092994046,\n",
       " 'must': 3.302585092994046,\n",
       " 'deny': 3.302585092994046,\n",
       " 'evolution.': 3.302585092994046,\n",
       " 'Pastor': 3.302585092994046,\n",
       " 'Rick': 3.302585092994046,\n",
       " 'Warren,': 3.302585092994046,\n",
       " 'author': 3.302585092994046,\n",
       " '\"The': 3.302585092994046,\n",
       " 'Life,\"': 3.302585092994046,\n",
       " 'reflects': 3.302585092994046,\n",
       " 'his': 3.302585092994046,\n",
       " 'crisis': 3.302585092994046,\n",
       " 'purpose': 3.302585092994046,\n",
       " 'wake': 3.302585092994046,\n",
       " \"book's\": 3.302585092994046,\n",
       " 'wild': 3.302585092994046,\n",
       " 'success.': 3.302585092994046,\n",
       " 'He': 1.916290731874155,\n",
       " 'explains': 3.302585092994046,\n",
       " 'belief': 3.302585092994046,\n",
       " \"God's\": 3.302585092994046,\n",
       " 'intention': 3.302585092994046,\n",
       " 'is': 3.302585092994046,\n",
       " 'each': 3.302585092994046,\n",
       " 'us': 3.302585092994046,\n",
       " 'use': 3.302585092994046,\n",
       " 'our': 3.302585092994046,\n",
       " 'talents': 3.302585092994046,\n",
       " 'influence': 3.302585092994046,\n",
       " 'do': 3.302585092994046,\n",
       " 'good.': 3.302585092994046}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inverseDocumentFrequency(term, allDocuments):\n",
    "    numDocumentsWithThisTerm = 0\n",
    "    for doc in range (0, len(allDocuments)):\n",
    "        if term.lower() in allDocuments[doc].lower().split():\n",
    "            numDocumentsWithThisTerm = numDocumentsWithThisTerm + 1\n",
    " \n",
    "    if numDocumentsWithThisTerm > 0:\n",
    "        return 1.0 + math.log(float(len(allDocuments)) / numDocumentsWithThisTerm)\n",
    "    else:\n",
    "        return 1.0\n",
    "    \n",
    "def compute_idf(documents):\n",
    "    idf_dict = {}\n",
    "    for doc in documents:\n",
    "        sentence = doc.split()\n",
    "        for word in sentence:\n",
    "            idf_dict[word] = inverseDocumentFrequency(word, documents)\n",
    "    return idf_dict\n",
    "idf_dict = compute_idf(documents)\n",
    "\n",
    "compute_idf(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016677,
     "end_time": "2021-03-10T09:03:36.980514",
     "exception": false,
     "start_time": "2021-03-10T09:03:36.963837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3.TF * IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016682,
     "end_time": "2021-03-10T09:03:37.013870",
     "exception": false,
     "start_time": "2021-03-10T09:03:36.997188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Remember we are trying to find out relevant documents for the query: **life learning**\n",
    "\n",
    "* For each term in the query multiply its normalized term frequency with its IDF on each document. \n",
    "* In Document1 for the term life the normalized term frequency is 0.1 and its IDF is 1.405465108. \n",
    "* Multiplying them together we get 0.140550715 (0.1 * 1.405465108). \n",
    "* \n",
    "Given below is TF * IDF calculations for life and learning in all the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T09:03:37.070339Z",
     "iopub.status.busy": "2021-03-10T09:03:37.069470Z",
     "iopub.status.idle": "2021-03-10T09:03:37.073407Z",
     "shell.execute_reply": "2021-03-10T09:03:37.072766Z"
    },
    "papermill": {
     "duration": 0.043109,
     "end_time": "2021-03-10T09:03:37.073525",
     "exception": false,
     "start_time": "2021-03-10T09:03:37.030416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   doc  humanity       and     humor  earn  more      than  half        of  \\\n",
      "0  0.0  0.000000  0.058245  0.000000   0.0   0.0  0.157266   0.0  0.000000   \n",
      "1  1.0  0.084682  0.031363  0.084682   0.0   0.0  0.000000   0.0  0.000000   \n",
      "2  2.0  0.000000  0.039456  0.000000   0.0   0.0  0.000000   0.0  0.054618   \n",
      "3  3.0  0.000000  0.039456  0.000000   0.0   0.0  0.000000   0.0  0.000000   \n",
      "4  4.0  0.000000  0.047044  0.000000   0.0   0.0  0.000000   0.0  0.065121   \n",
      "5  5.0  0.000000  0.064376  0.000000   0.0   0.0  0.000000   0.0  0.000000   \n",
      "6  6.0  0.000000  0.000000  0.000000   0.0   0.0  0.000000   0.0  0.049798   \n",
      "7  7.0  0.000000  0.038223  0.000000   0.0   0.0  0.000000   0.0  0.052911   \n",
      "8  8.0  0.000000  0.000000  0.000000   0.0   0.0  0.000000   0.0  0.000000   \n",
      "9  9.0  0.000000  0.027799  0.000000   0.0   0.0  0.000000   0.0  0.153922   \n",
      "\n",
      "        the  population   by       New      York     Times  \n",
      "0  0.000000         0.0  0.0  0.000000  0.000000  0.000000  \n",
      "1  0.034787         0.0  0.0  0.000000  0.000000  0.000000  \n",
      "2  0.000000         0.0  0.0  0.106535  0.106535  0.106535  \n",
      "3  0.043764         0.0  0.0  0.000000  0.000000  0.000000  \n",
      "4  0.104360         0.0  0.0  0.000000  0.000000  0.000000  \n",
      "5  0.142808         0.0  0.0  0.000000  0.000000  0.000000  \n",
      "6  0.000000         0.0  0.0  0.000000  0.000000  0.000000  \n",
      "7  0.169584         0.0  0.0  0.000000  0.000000  0.000000  \n",
      "8  0.000000         0.0  0.0  0.000000  0.000000  0.000000  \n",
      "9  0.030834         0.0  0.0  0.000000  0.000000  0.000000  \n"
     ]
    }
   ],
   "source": [
    "# tf-idf score across all docs for the query string(\"life learning\")\n",
    "def compute_tfidf_with_alldocs(documents , query):\n",
    "    tf_idf = []\n",
    "    index = 0\n",
    "    query_tokens = query.split()\n",
    "    df = pd.DataFrame(columns=['doc'] + query_tokens)\n",
    "    for doc in documents:\n",
    "        df['doc'] = np.arange(0 , len(documents))\n",
    "        doc_num = tf_doc[index]\n",
    "        sentence = doc.split()\n",
    "        for word in sentence:\n",
    "            for text in query_tokens:\n",
    "                if(text == word):\n",
    "                    idx = sentence.index(word)\n",
    "                    tf_idf_score = doc_num[word] * idf_dict[word]\n",
    "                    tf_idf.append(tf_idf_score)\n",
    "                    df.iloc[index, df.columns.get_loc(word)] = tf_idf_score\n",
    "        index += 1\n",
    "    df.fillna(0 , axis=1, inplace=True)\n",
    "    return tf_idf , df\n",
    "            \n",
    "tf_idf , df = compute_tfidf_with_alldocs(documents , query)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017202,
     "end_time": "2021-03-10T09:03:37.107473",
     "exception": false,
     "start_time": "2021-03-10T09:03:37.090271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4.Vector Space Models and Representation  – Cosine Similarity\n",
    "\n",
    "The set of documents in a collection then is viewed as a set of vectors in a vector space. Each term will have its own axis. Using the formula given below we can find out the similarity between any two documents.\n",
    "\n",
    "* > Cosine Similarity (d1, d2) =  Dot product(d1, d2) / ||d1|| * ||d2||\n",
    "* > Dot product (d1,d2) = d1[0] * d2[0] + d1[1] * d2[1] * … * d1[n] * d2[n]\n",
    "* > ||d1|| = square root(d1[0]2 + d1[1]2 + ... + d1[n]2)\n",
    "* > ||d2|| = square root(d2[0]2 + d2[1]2 + ... + d2[n]2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017628,
     "end_time": "2021-03-10T09:03:37.195478",
     "exception": false,
     "start_time": "2021-03-10T09:03:37.177850",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Vectors deals only with numbers. In this example we are dealing with text documents. This was the reason why we used TF and IDF to convert text into numbers so that it can be represented by a vecto\n",
    "\n",
    "\n",
    "The query entered by the user can also be represented as a vector. We will calculate the TF*IDF for the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T09:03:37.240068Z",
     "iopub.status.busy": "2021-03-10T09:03:37.239003Z",
     "iopub.status.idle": "2021-03-10T09:03:37.242904Z",
     "shell.execute_reply": "2021-03-10T09:03:37.243704Z"
    },
    "papermill": {
     "duration": 0.030684,
     "end_time": "2021-03-10T09:03:37.243916",
     "exception": false,
     "start_time": "2021-03-10T09:03:37.213232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'humanity': 0.07142857142857142, 'and': 0.07142857142857142, 'humor': 0.07142857142857142, 'earn': 0.07142857142857142, 'more': 0.07142857142857142, 'than': 0.07142857142857142, 'half': 0.07142857142857142, 'of': 0.07142857142857142, 'the': 0.07142857142857142, 'population': 0.07142857142857142, 'by': 0.07142857142857142, 'New': 0.07142857142857142, 'York': 0.07142857142857142, 'Times': 0.07142857142857142}\n"
     ]
    }
   ],
   "source": [
    "#Normalized TF for the query string(\"life learning\")\n",
    "def compute_query_tf(query):\n",
    "    query_norm_tf = {}\n",
    "    tokens = query.split()\n",
    "    for word in tokens:\n",
    "        query_norm_tf[word] = termFrequency(word , query)\n",
    "    return query_norm_tf\n",
    "query_norm_tf = compute_query_tf(query)\n",
    "print(query_norm_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T09:03:37.289898Z",
     "iopub.status.busy": "2021-03-10T09:03:37.289226Z",
     "iopub.status.idle": "2021-03-10T09:03:37.292791Z",
     "shell.execute_reply": "2021-03-10T09:03:37.292120Z"
    },
    "papermill": {
     "duration": 0.028473,
     "end_time": "2021-03-10T09:03:37.292916",
     "exception": false,
     "start_time": "2021-03-10T09:03:37.264443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'humanity': 3.302585092994046, 'and': 1.2231435513142097, 'humor': 3.302585092994046, 'earn': 1.0, 'more': 1.0, 'than': 3.302585092994046, 'half': 1.0, 'of': 1.6931471805599454, 'the': 1.3566749439387324, 'population': 1.0, 'by': 1.0, 'New': 3.302585092994046, 'York': 3.302585092994046, 'Times': 3.302585092994046}\n"
     ]
    }
   ],
   "source": [
    "#idf score for the query string(\"life learning\")\n",
    "def compute_query_idf(query):\n",
    "    idf_dict_qry = {}\n",
    "    sentence = query.split()\n",
    "    \n",
    "    for word in sentence:\n",
    "        idf_dict_qry[word] = inverseDocumentFrequency(word ,documents)\n",
    "    return idf_dict_qry\n",
    "idf_dict_qry = compute_query_idf(query)\n",
    "print(idf_dict_qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T09:03:37.337403Z",
     "iopub.status.busy": "2021-03-10T09:03:37.336630Z",
     "iopub.status.idle": "2021-03-10T09:03:37.340919Z",
     "shell.execute_reply": "2021-03-10T09:03:37.340248Z"
    },
    "papermill": {
     "duration": 0.029071,
     "end_time": "2021-03-10T09:03:37.341035",
     "exception": false,
     "start_time": "2021-03-10T09:03:37.311964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'humanity': 0.2358989352138604, 'and': 0.08736739652244355, 'humor': 0.2358989352138604, 'earn': 0.07142857142857142, 'more': 0.07142857142857142, 'than': 0.2358989352138604, 'half': 0.07142857142857142, 'of': 0.12093908432571038, 'the': 0.09690535313848088, 'population': 0.07142857142857142, 'by': 0.07142857142857142, 'New': 0.2358989352138604, 'York': 0.2358989352138604, 'Times': 0.2358989352138604}\n"
     ]
    }
   ],
   "source": [
    "#tf-idf score for the query string(\"life learning\")\n",
    "def compute_query_tfidf(query):\n",
    "    tfidf_dict_qry = {}\n",
    "    sentence = query.split()\n",
    "    for word in sentence:\n",
    "        tfidf_dict_qry[word] = query_norm_tf[word] * idf_dict_qry[word]\n",
    "    return tfidf_dict_qry\n",
    "tfidf_dict_qry = compute_query_tfidf(query)\n",
    "print(tfidf_dict_qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01903,
     "end_time": "2021-03-10T09:03:37.379287",
     "exception": false,
     "start_time": "2021-03-10T09:03:37.360257",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let us now calculate the cosine similarity of the query and Document1.\n",
    "\n",
    "Cosine Similarity(Query,Document1) = Dot product(Query, Document1) / ||Query|| * ||Document1||\n",
    "\n",
    "Dot product(Query, Document1) \n",
    "     = ((0.702753576) * (0.140550715) + (0.702753576)*(0.140550715))\n",
    "     = 0.197545035151\n",
    "\n",
    "||Query|| = sqrt((0.702753576)2 + (0.702753576)2) = 0.993843638185\n",
    "\n",
    "||Document1|| = sqrt((0.140550715)2 + (0.140550715)2) = 0.198768727354\n",
    "\n",
    "Cosine Similarity(Query, Document) = 0.197545035151 / (0.993843638185) * (0.198768727354)\n",
    "                                        = 0.197545035151 / 0.197545035151\n",
    "                                        = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T09:03:37.430713Z",
     "iopub.status.busy": "2021-03-10T09:03:37.429853Z",
     "iopub.status.idle": "2021-03-10T09:03:37.434083Z",
     "shell.execute_reply": "2021-03-10T09:03:37.433448Z"
    },
    "papermill": {
     "duration": 0.035809,
     "end_time": "2021-03-10T09:03:37.434194",
     "exception": false,
     "start_time": "2021-03-10T09:03:37.398385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Cosine Similarity(Query,Document1) = Dot product(Query, Document1) / ||Query|| * ||Document1||\n",
    "\n",
    "\"\"\"\n",
    "Example : Dot roduct(Query, Document1) \n",
    "\n",
    "     life:\n",
    "     = tfidf(life w.r.t query) * tfidf(life w.r.t Document1) +  / \n",
    "     sqrt(tfidf(life w.r.t query)) * \n",
    "     sqrt(tfidf(life w.r.t doc1))\n",
    "     \n",
    "     learning:\n",
    "     =tfidf(learning w.r.t query) * tfidf(learning w.r.t Document1)/\n",
    "     sqrt(tfidf(learning w.r.t query)) * \n",
    "     sqrt(tfidf(learning w.r.t doc1))\n",
    "\n",
    "\"\"\"\n",
    "def cosine_similarity(tfidf_dict_qry, df , query , doc_num):\n",
    "    dot_product = 0\n",
    "    qry_mod = 0\n",
    "    doc_mod = 0\n",
    "    tokens = query.split()\n",
    "   \n",
    "    for keyword in tokens:\n",
    "        dot_product += tfidf_dict_qry[keyword] * df[keyword][df['doc'] == doc_num]\n",
    "        #||Query||\n",
    "        qry_mod += tfidf_dict_qry[keyword] * tfidf_dict_qry[keyword]\n",
    "        #||Document||\n",
    "        doc_mod += df[keyword][df['doc'] == doc_num] * df[keyword][df['doc'] == doc_num]\n",
    "    qry_mod = np.sqrt(qry_mod)\n",
    "    doc_mod = np.sqrt(doc_mod)\n",
    "    #implement formula\n",
    "    denominator = qry_mod * doc_mod\n",
    "    cos_sim = dot_product/denominator\n",
    "     \n",
    "    return cos_sim\n",
    "\n",
    "from collections.abc import Iterable\n",
    "def flatten(lis):\n",
    "     for item in lis:\n",
    "        if isinstance(item, Iterable) and not isinstance(item, str):\n",
    "             for x in flatten(item):\n",
    "                yield x\n",
    "        else:        \n",
    "             yield item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T09:03:37.482520Z",
     "iopub.status.busy": "2021-03-10T09:03:37.481607Z",
     "iopub.status.idle": "2021-03-10T09:03:37.517567Z",
     "shell.execute_reply": "2021-03-10T09:03:37.516919Z"
    },
    "papermill": {
     "duration": 0.063763,
     "end_time": "2021-03-10T09:03:37.517700",
     "exception": false,
     "start_time": "2021-03-10T09:03:37.453937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Document1', 'Document2', 'Document3', 'Document4', 'Document5', 'Document6', 'Document7', 'Document8', 'Document9', 'Document10']\n",
      "[0.4022738278216581, 0.5728376678131828, 0.6955835188576667, 0.20864642225151528, 0.26832898865267185, 0.19868979306180182, 0.19339735005639636, 0.2303230524496217, nan, 0.2410578874472035]\n"
     ]
    }
   ],
   "source": [
    "def rank_similarity_docs(data):\n",
    "    cos_sim =[]\n",
    "    for doc_num in range(0 , len(data)):\n",
    "        cos_sim.append(cosine_similarity(tfidf_dict_qry, df , query , doc_num).tolist())\n",
    "    return cos_sim\n",
    "similarity_docs = rank_similarity_docs(documents)\n",
    "doc_names = [f\"Document{i+1}\" for i in range(len(documents))]\n",
    "print(doc_names)\n",
    "print(list(flatten(similarity_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.4022738278216581],\n",
       " [0.5728376678131828],\n",
       " [0.6955835188576667],\n",
       " [0.20864642225151528],\n",
       " [0.26832898865267185],\n",
       " [0.19868979306180182],\n",
       " [0.19339735005639636],\n",
       " [0.2303230524496217],\n",
       " [nan],\n",
       " [0.2410578874472035]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "papermill": {
   "duration": 6.967548,
   "end_time": "2021-03-10T09:03:38.716094",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-03-10T09:03:31.748546",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
